{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1766056607133
        }
      },
      "outputs": [],
      "source": [
        "import os, math, json, re, time, uuid, random\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ML libs\n",
        "from astropy.io import fits\n",
        "from astropy.cosmology import Planck18 as cosmo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, roc_auc_score, brier_score_loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "# nflows (install if missing)\n",
        "try:\n",
        "    from nflows.flows import Flow\n",
        "    from nflows.distributions import StandardNormal\n",
        "    from nflows.transforms import CompositeTransform, MaskedAffineAutoregressiveTransform, ReversePermutation\n",
        "except Exception:\n",
        "    raise RuntimeError(\"nflows is required. Install: pip install nflows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1766056608733
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ----------------------\n",
        "# Config & deterministic\n",
        "# ----------------------\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "FEATURES = ['u','g','r','i','z','g-r','u-g','r-i','M_r','redshift']\n",
        "\n",
        "# Quick-run flags (set SUBSET=None to use full data)\n",
        "SUBSET = 10000        # None or int\n",
        "QUICK_EPOCHS_A = 20\n",
        "QUICK_EPOCHS_B = 10\n",
        "QUICK_EPOCHS_C = 10\n",
        "USE_QUICK = True      # toggle quick-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1766056630170
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXP_ROOT: d:\\Libraries\\Desktop\\pinn_v2\\exp_outputs\\run_20260103_174944_21142808\n"
          ]
        }
      ],
      "source": [
        "# ----------------------\n",
        "# Experiment directories\n",
        "# ----------------------\n",
        "ROOT = Path.cwd()\n",
        "BASE_EXP_ROOT = ROOT / \"exp_outputs\"\n",
        "BASE_EXP_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_id = uuid.uuid4().hex[:8]\n",
        "EXP_ROOT = BASE_EXP_ROOT / f\"run_{timestamp}_{run_id}\"\n",
        "EXP_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"EXP_ROOT:\", EXP_ROOT)\n",
        "\n",
        "# ----------------------\n",
        "# Utility functions\n",
        "# ----------------------\n",
        "def metrics(y_true, y_pred):\n",
        "    return {\"rmse\": math.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "            \"mae\": mean_absolute_error(y_true, y_pred),\n",
        "            \"r2\": r2_score(y_true, y_pred)}\n",
        "\n",
        "def fits_to_df_safe(fname, ext=1):\n",
        "    with fits.open(fname, memmap=True) as hdul:\n",
        "        data = hdul[ext].data\n",
        "        names = data.dtype.names\n",
        "        out = {}\n",
        "        for n in names:\n",
        "            col = data[n]\n",
        "            # convert big-endian\n",
        "            if getattr(col, \"dtype\", None) is not None and col.dtype.byteorder in (\">\", \"!\"):\n",
        "                col = col.byteswap().view(col.dtype.newbyteorder(\"=\"))\n",
        "            # handle structured arrays\n",
        "            try:\n",
        "                first = col[0]\n",
        "            except Exception:\n",
        "                out[n] = col\n",
        "                continue\n",
        "            if np.ndim(first) > 0:\n",
        "                arr = np.vstack(col)\n",
        "                for j in range(arr.shape[1]):\n",
        "                    out[f\"{n}_{j}\"] = arr[:, j]\n",
        "            else:\n",
        "                out[n] = col\n",
        "    return pd.DataFrame(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1766056824682
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading gal_info_dr7_v5_2.fit.gz → d:\\Libraries\\Desktop\\pinn_v2\\exp_outputs\\run_20260103_174944_21142808\\raw_data\\gal_info_dr7_v5_2.fit.gz\n",
            "Downloading gal_totsfr_dr7_v5_2.fits.gz → d:\\Libraries\\Desktop\\pinn_v2\\exp_outputs\\run_20260103_174944_21142808\\raw_data\\gal_totsfr_dr7_v5_2.fits.gz\n",
            "Downloading totlgm_dr7_v5_2.fit.gz → d:\\Libraries\\Desktop\\pinn_v2\\exp_outputs\\run_20260103_174944_21142808\\raw_data\\totlgm_dr7_v5_2.fit.gz\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'd:\\\\Libraries\\\\Desktop\\\\pinn_v2\\\\exp_outputs\\\\run_20260103_174944_21142808\\\\raw_data\\\\gal_info_dr7_v5_2.fit.gz'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExists:\u001b[39m\u001b[33m\"\u001b[39m, local_path)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Load FITS → DataFrames\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m df_info = \u001b[43mfits_to_df_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_files\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgal_info\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m df_sfr  = fits_to_df_safe(local_files[\u001b[33m\"\u001b[39m\u001b[33mgal_sfr\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     54\u001b[39m df_mass = fits_to_df_safe(local_files[\u001b[33m\"\u001b[39m\u001b[33mgal_mass\u001b[39m\u001b[33m\"\u001b[39m])\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mfits_to_df_safe\u001b[39m\u001b[34m(fname, ext)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfits_to_df_safe\u001b[39m(fname, ext=\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hdul:\n\u001b[32m     25\u001b[39m         data = hdul[ext].data\n\u001b[32m     26\u001b[39m         names = data.dtype.names\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Savindu\\miniconda3\\Lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py:220\u001b[39m, in \u001b[36mfitsopen\u001b[39m\u001b[34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Savindu\\miniconda3\\Lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py:484\u001b[39m, in \u001b[36mHDUList.fromfile\u001b[39m\u001b[34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfromfile\u001b[39m(\n\u001b[32m    467\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    475\u001b[39m     **kwargs,\n\u001b[32m    476\u001b[39m ):\n\u001b[32m    477\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[33;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[32m    479\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    482\u001b[39m \u001b[33;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Savindu\\miniconda3\\Lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py:1186\u001b[39m, in \u001b[36mHDUList._readfrom\u001b[39m\u001b[34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[32m   1185\u001b[39m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1186\u001b[39m         fileobj = \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[32m   1196\u001b[39m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[32m   1197\u001b[39m     mode = fileobj.mode\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Savindu\\miniconda3\\Lib\\site-packages\\astropy\\io\\fits\\file.py:240\u001b[39m, in \u001b[36m_File.__init__\u001b[39m\u001b[34m(self, fileobj, mode, memmap, overwrite, cache, use_fsspec, fsspec_kwargs, decompress_in_memory)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m._open_fileobj(fileobj, mode, overwrite)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m._open_filelike(fileobj, mode, overwrite)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Savindu\\miniconda3\\Lib\\site-packages\\astropy\\io\\fits\\file.py:700\u001b[39m, in \u001b[36m_File._open_filename\u001b[39m\u001b[34m(self, filename, mode, overwrite)\u001b[39m\n\u001b[32m    697\u001b[39m ext = os.path.splitext(\u001b[38;5;28mself\u001b[39m.name)[\u001b[32m1\u001b[39m]\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._try_read_compressed(\u001b[38;5;28mself\u001b[39m.name, magic, mode, ext=ext):\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIO_FITS_MODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m     \u001b[38;5;28mself\u001b[39m.close_on_error = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[32m    704\u001b[39m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'd:\\\\Libraries\\\\Desktop\\\\pinn_v2\\\\exp_outputs\\\\run_20260103_174944_21142808\\\\raw_data\\\\gal_info_dr7_v5_2.fit.gz'"
          ]
        }
      ],
      "source": [
        "# ----------------------\n",
        "# Data load / preprocess\n",
        "# ----------------------\n",
        "\n",
        "# ----------------------\n",
        "# Paths\n",
        "# ----------------------\n",
        "\n",
        "EXP_ROOT = Path(EXP_ROOT)  # ensure Path\n",
        "raw_data_dir = EXP_ROOT / \"raw_data\"\n",
        "raw_data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "csv_saved = EXP_ROOT / \"mpa_dr7_clean.csv\"\n",
        "\n",
        "# ----------------------\n",
        "# Load cached CSV if exists\n",
        "# ----------------------\n",
        "\n",
        "if csv_saved.exists():\n",
        "    print(\"Loading saved cleaned CSV:\", csv_saved)\n",
        "    df_final = pd.read_csv(csv_saved)\n",
        "\n",
        "else:\n",
        "    # ----------------------\n",
        "    # Download FITS files (to EXP_ROOT/raw_data)\n",
        "    # ----------------------\n",
        "\n",
        "    base = \"https://wwwmpa.mpa-garching.mpg.de/SDSS/DR7/Data\"\n",
        "    files = {\n",
        "        \"gal_info\": \"gal_info_dr7_v5_2.fit.gz\",\n",
        "        \"gal_sfr\":  \"gal_totsfr_dr7_v5_2.fits.gz\",\n",
        "        \"gal_mass\": \"totlgm_dr7_v5_2.fit.gz\"\n",
        "    }\n",
        "\n",
        "    local_files = {}\n",
        "\n",
        "    for name, fn in files.items():\n",
        "        local_path = raw_data_dir / fn\n",
        "        local_files[name] = local_path\n",
        "\n",
        "        if not local_path.exists():\n",
        "            url = f\"{base}/{fn}\"\n",
        "            print(f\"Downloading {fn} → {local_path}\")\n",
        "            os.system(f\"wget -q {url} -O {local_path}\")\n",
        "        else:\n",
        "            print(\"Exists:\", local_path)\n",
        "\n",
        "    # ----------------------\n",
        "    # Load FITS → DataFrames\n",
        "    # ----------------------\n",
        "\n",
        "    df_info = fits_to_df_safe(local_files[\"gal_info\"])\n",
        "    df_sfr  = fits_to_df_safe(local_files[\"gal_sfr\"])\n",
        "    df_mass = fits_to_df_safe(local_files[\"gal_mass\"])\n",
        "\n",
        "    # Prefix to avoid column collisions\n",
        "    df = pd.concat(\n",
        "        [\n",
        "            df_info,\n",
        "            df_sfr.add_prefix(\"SFR_\"),\n",
        "            df_mass.add_prefix(\"MASS_\")\n",
        "        ],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    print(\"Raw rows:\", len(df))\n",
        "\n",
        "    # ----------------------\n",
        "    # Required column mapping\n",
        "    # ----------------------\n",
        "\n",
        "    required_mapping = {\n",
        "        'u': 'PLUG_MAG_0',\n",
        "        'g': 'PLUG_MAG_1',\n",
        "        'r': 'PLUG_MAG_2',\n",
        "        'i': 'PLUG_MAG_3',\n",
        "        'z': 'PLUG_MAG_4',\n",
        "        'redshift': 'Z',\n",
        "        'logM_true': 'MASS_MEDIAN',\n",
        "        'logSFR_true': 'SFR_AVG'\n",
        "    }\n",
        "\n",
        "    dfc = df.copy()\n",
        "\n",
        "    for out_col, src in required_mapping.items():\n",
        "        if src in dfc.columns:\n",
        "            series = dfc[src]\n",
        "\n",
        "            if series.dtype == object:\n",
        "                def scalarize(x):\n",
        "                    try:\n",
        "                        if hasattr(x, '__len__') and not isinstance(x, (str, bytes)):\n",
        "                            return float(x[0])\n",
        "                        return float(x)\n",
        "                    except Exception:\n",
        "                        return np.nan\n",
        "\n",
        "                dfc[out_col] = series.map(scalarize)\n",
        "            else:\n",
        "                dfc[out_col] = pd.to_numeric(series, errors='coerce')\n",
        "        else:\n",
        "            dfc[out_col] = np.nan\n",
        "\n",
        "    # ----------------------\n",
        "    # Derived colors\n",
        "    # ----------------------\n",
        "\n",
        "    dfc['g-r'] = dfc['g'] - dfc['r']\n",
        "    dfc['u-g'] = dfc['u'] - dfc['g']\n",
        "    dfc['r-i'] = dfc['r'] - dfc['i']\n",
        "\n",
        "    # ----------------------\n",
        "    # Absolute magnitude M_r\n",
        "    # ----------------------\n",
        "\n",
        "    z_valid = (\n",
        "        dfc['redshift'].notna() &\n",
        "        (dfc['redshift'] > 0) &\n",
        "        (dfc['redshift'] < 1.0)\n",
        "    )\n",
        "\n",
        "    dl_pc = np.full(len(dfc), np.nan)\n",
        "\n",
        "    if z_valid.sum() > 0:\n",
        "        dl_pc_vals = cosmo.luminosity_distance(\n",
        "            dfc.loc[z_valid, 'redshift']\n",
        "        ).to('pc').value\n",
        "        dl_pc[z_valid] = dl_pc_vals\n",
        "\n",
        "    dfc['M_r'] = np.nan\n",
        "    mask = (~np.isnan(dl_pc)) & (dl_pc > 0) & dfc['r'].notna()\n",
        "    dfc.loc[mask, 'M_r'] = dfc.loc[mask, 'r'] - 5*np.log10(dl_pc[mask]) + 5\n",
        "\n",
        "    # ----------------------\n",
        "    # Sentinel + numeric cleaning\n",
        "    # ----------------------\n",
        "\n",
        "    for b in ['u', 'g', 'r', 'i', 'z']:\n",
        "        if b in dfc.columns:\n",
        "            dfc.loc[dfc[b] <= -100, b] = np.nan\n",
        "            dfc.loc[dfc[b] < -50, b] = np.nan\n",
        "\n",
        "    dfc = dfc.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    dfc['logM_true'] = pd.to_numeric(dfc['logM_true'], errors='coerce')\n",
        "    dfc['logSFR_true'] = pd.to_numeric(dfc['logSFR_true'], errors='coerce')\n",
        "\n",
        "    # Physical bounds\n",
        "    dfc = dfc[(dfc['logM_true'] >= 5) & (dfc['logM_true'] <= 13)]\n",
        "    dfc = dfc[(dfc['logSFR_true'] >= -5) & (dfc['logSFR_true'] <= 2)]\n",
        "\n",
        "    # ----------------------\n",
        "    # Final selection\n",
        "    # ----------------------\n",
        "\n",
        "    essential = [\n",
        "        'u','g','r','i','z',\n",
        "        'g-r','u-g','r-i',\n",
        "        'M_r','redshift',\n",
        "        'logM_true','logSFR_true'\n",
        "    ]\n",
        "\n",
        "    df_final = (\n",
        "        dfc\n",
        "        .dropna(subset=essential)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    csv_saved.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df_final.to_csv(csv_saved, index=False)\n",
        "\n",
        "    print(\"Saved cleaned CSV:\", csv_saved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw dataset shape: (927552, 57)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PLATEID</th>\n",
              "      <th>MJD</th>\n",
              "      <th>FIBERID</th>\n",
              "      <th>PHOTOID_0</th>\n",
              "      <th>PHOTOID_1</th>\n",
              "      <th>PHOTOID_2</th>\n",
              "      <th>PHOTOID_3</th>\n",
              "      <th>PHOTOID_4</th>\n",
              "      <th>RA</th>\n",
              "      <th>DEC</th>\n",
              "      <th>...</th>\n",
              "      <th>SFR_P2P5</th>\n",
              "      <th>SFR_P84</th>\n",
              "      <th>SFR_P97P5</th>\n",
              "      <th>MASS_MEDIAN</th>\n",
              "      <th>MASS_P16</th>\n",
              "      <th>MASS_P84</th>\n",
              "      <th>MASS_P2P5</th>\n",
              "      <th>MASS_P97P5</th>\n",
              "      <th>MASS_MODE</th>\n",
              "      <th>MASS_AVG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>266</td>\n",
              "      <td>51602</td>\n",
              "      <td>1</td>\n",
              "      <td>756</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>206</td>\n",
              "      <td>129</td>\n",
              "      <td>146.71420</td>\n",
              "      <td>-1.041304</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.800000</td>\n",
              "      <td>-0.103459</td>\n",
              "      <td>0.363235</td>\n",
              "      <td>10.294701</td>\n",
              "      <td>10.202774</td>\n",
              "      <td>10.389574</td>\n",
              "      <td>10.124110</td>\n",
              "      <td>10.476275</td>\n",
              "      <td>10.293333</td>\n",
              "      <td>10.308453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>266</td>\n",
              "      <td>51602</td>\n",
              "      <td>2</td>\n",
              "      <td>756</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>208</td>\n",
              "      <td>235</td>\n",
              "      <td>146.91945</td>\n",
              "      <td>-0.990492</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.630000</td>\n",
              "      <td>0.736875</td>\n",
              "      <td>1.198334</td>\n",
              "      <td>11.162018</td>\n",
              "      <td>11.042439</td>\n",
              "      <td>11.284745</td>\n",
              "      <td>10.943877</td>\n",
              "      <td>11.420699</td>\n",
              "      <td>11.226666</td>\n",
              "      <td>11.176508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>266</td>\n",
              "      <td>51602</td>\n",
              "      <td>4</td>\n",
              "      <td>752</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>228</td>\n",
              "      <td>146.85983</td>\n",
              "      <td>-0.808902</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.402941</td>\n",
              "      <td>-0.077523</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>11.373624</td>\n",
              "      <td>11.298348</td>\n",
              "      <td>11.466687</td>\n",
              "      <td>11.231741</td>\n",
              "      <td>11.550502</td>\n",
              "      <td>11.389999</td>\n",
              "      <td>11.391095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>266</td>\n",
              "      <td>51602</td>\n",
              "      <td>5</td>\n",
              "      <td>752</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>293</td>\n",
              "      <td>146.76340</td>\n",
              "      <td>-0.810433</td>\n",
              "      <td>...</td>\n",
              "      <td>-99.000000</td>\n",
              "      <td>-99.000000</td>\n",
              "      <td>-99.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>266</td>\n",
              "      <td>51602</td>\n",
              "      <td>6</td>\n",
              "      <td>756</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>208</td>\n",
              "      <td>268</td>\n",
              "      <td>146.96390</td>\n",
              "      <td>-0.545003</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.075000</td>\n",
              "      <td>0.028417</td>\n",
              "      <td>0.448718</td>\n",
              "      <td>9.958836</td>\n",
              "      <td>9.864179</td>\n",
              "      <td>10.059154</td>\n",
              "      <td>9.768107</td>\n",
              "      <td>10.156217</td>\n",
              "      <td>9.943334</td>\n",
              "      <td>9.972836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   PLATEID    MJD  FIBERID  PHOTOID_0  PHOTOID_1  PHOTOID_2  PHOTOID_3  \\\n",
              "0      266  51602        1        756          1          1        206   \n",
              "1      266  51602        2        756          1          1        208   \n",
              "2      266  51602        4        752          1          2         22   \n",
              "3      266  51602        5        752          1          2         21   \n",
              "4      266  51602        6        756          1          2        208   \n",
              "\n",
              "   PHOTOID_4         RA       DEC  ...   SFR_P2P5    SFR_P84  SFR_P97P5  \\\n",
              "0        129  146.71420 -1.041304  ...  -1.800000  -0.103459   0.363235   \n",
              "1        235  146.91945 -0.990492  ...  -1.630000   0.736875   1.198334   \n",
              "2        228  146.85983 -0.808902  ...  -2.402941  -0.077523   0.413793   \n",
              "3        293  146.76340 -0.810433  ... -99.000000 -99.000000 -99.000000   \n",
              "4        268  146.96390 -0.545003  ...  -1.075000   0.028417   0.448718   \n",
              "\n",
              "   MASS_MEDIAN   MASS_P16   MASS_P84  MASS_P2P5 MASS_P97P5  MASS_MODE  \\\n",
              "0    10.294701  10.202774  10.389574  10.124110  10.476275  10.293333   \n",
              "1    11.162018  11.042439  11.284745  10.943877  11.420699  11.226666   \n",
              "2    11.373624  11.298348  11.466687  11.231741  11.550502  11.389999   \n",
              "3    -1.000000  -1.000000  -1.000000  -1.000000  -1.000000  -1.000000   \n",
              "4     9.958836   9.864179  10.059154   9.768107  10.156217   9.943334   \n",
              "\n",
              "    MASS_AVG  \n",
              "0  10.308453  \n",
              "1  11.176508  \n",
              "2  11.391095  \n",
              "3  -1.000000  \n",
              "4   9.972836  \n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge exactly as in preprocessing\n",
        "df_raw = pd.read_csv(\"mpa_dr7_raw_merged.csv\")\n",
        "\n",
        "print(\"Raw dataset shape:\", df_raw.shape)\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_raw = [\n",
        "    'PLUG_MAG_0','PLUG_MAG_1','PLUG_MAG_2',\n",
        "    'PLUG_MAG_3','PLUG_MAG_4',\n",
        "    'MASS_MEDIAN','SFR_AVG'\n",
        "]\n",
        "\n",
        "df_raw_sel = df_raw[features_raw].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "missing_pct = df_raw_sel.isna().mean() * 100\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(missing_pct.index, missing_pct.values, color=\"#1f77b4\")\n",
        "plt.ylabel(\"Missing Values (%)\")\n",
        "plt.title(\"Explicit Missing Values in Raw Dataset\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056825247
        }
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Arrays & splits\n",
        "# ----------------------\n",
        "X = df_final[FEATURES].values.astype(np.float32)\n",
        "yM = df_final['logM_true'].values.astype(np.float32)\n",
        "yS = df_final['logSFR_true'].values.astype(np.float32)\n",
        "\n",
        "idx_all = np.arange(len(X))\n",
        "idx_temp, idx_test = train_test_split(idx_all, test_size=0.20, random_state=SEED)\n",
        "idx_train, idx_val = train_test_split(idx_temp, test_size=0.20, random_state=SEED)\n",
        "\n",
        "X_train, X_val, X_test = X[idx_train], X[idx_val], X[idx_test]\n",
        "yM_train, yM_val, yM_test = yM[idx_train], yM[idx_val], yM[idx_test]\n",
        "yS_train, yS_val, yS_test = yS[idx_train], yS[idx_val], yS[idx_test]\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_val_s   = scaler.transform(X_val)\n",
        "X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(scaler, os.path.join(EXP_ROOT, \"scaler.joblib\"))\n",
        "print(\"Shapes:\", X_train_s.shape, X_val_s.shape, X_test_s.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056825636
        }
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Quick-run subset override (safe)\n",
        "# ----------------------\n",
        "if USE_QUICK and (SUBSET is not None):\n",
        "    sel = np.random.RandomState(SEED).choice(np.arange(len(X_train_s)), size=min(SUBSET, len(X_train_s)), replace=False)\n",
        "    X_train_s = X_train_s[sel]\n",
        "    yM_train = yM_train[sel]\n",
        "    yS_train = yS_train[sel]\n",
        "    print(\"Quick-run active. Train subset size:\", X_train_s.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056826007
        }
      },
      "outputs": [],
      "source": [
        "# %% \n",
        "# Cell 5 (REPLACEMENT) — robust priors with GMM clustering & RANSAC (works with subset helper)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# --- Determine active training feature matrix in original (unscaled) units ---\n",
        "# We want X_train_unscaled to line up with yM_train length (handles subset scenario).\n",
        "if 'X_train' in globals() and X_train.shape[0] == yM_train.shape[0]:\n",
        "    X_train_unscaled = X_train\n",
        "elif 'X_train_s' in globals() and X_train_s.shape[0] == yM_train.shape[0] and 'scaler' in globals() and scaler is not None:\n",
        "    # inverse transform the scaled subset back to original units\n",
        "    X_train_unscaled = scaler.inverse_transform(X_train_s)\n",
        "elif 'X' in globals() and 'idx_train' in globals():\n",
        "    # fallback: select rows from full X by idx_train (useable when subset helper wasn't used)\n",
        "    X_train_unscaled = X[np.array(idx_train)]\n",
        "    if X_train_unscaled.shape[0] != yM_train.shape[0]:\n",
        "        raise RuntimeError(\"Fallback selection produced mismatched sizes. Re-run data split (Cell 4).\")\n",
        "else:\n",
        "    raise RuntimeError(\"Cannot infer training feature matrix matching yM_train length. Re-run Cell 4 or ensure subset helper didn't partially mutate arrays.\")\n",
        "\n",
        "print(\"GMM / priors will be computed on training rows:\", X_train_unscaled.shape[0])\n",
        "\n",
        "# --- GMM on (logM, logSFR) using the active training targets ---\n",
        "XY_train = np.vstack([yM_train, yS_train]).T\n",
        "gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=SEED)\n",
        "gmm.fit(XY_train)\n",
        "labels = gmm.predict(XY_train)\n",
        "comp_means = [XY_train[labels==c,1].mean() if (labels==c).sum()>0 else -1e9 for c in [0,1]]\n",
        "sf_label = int(np.argmax(comp_means))\n",
        "print(\"GMM component mean logSFRs:\", comp_means, \"-> SF label:\", sf_label)\n",
        "\n",
        "# prepare cluster dictionary\n",
        "clusters = {}\n",
        "for comp in [0,1]:\n",
        "    mask_comp = (labels == comp)\n",
        "    n_comp = int(mask_comp.sum())\n",
        "    # if component too small, fall back to full train (avoid unstable fits)\n",
        "    if n_comp < 10:\n",
        "        idx_comp_mask = np.ones(len(yM_train), dtype=bool)\n",
        "        print(f\"Warning: cluster {comp} too small ({n_comp}). Falling back to full train.\")\n",
        "    else:\n",
        "        idx_comp_mask = mask_comp\n",
        "\n",
        "    pred_cols = ['g-r', 'u-g', 'M_r', 'redshift']\n",
        "    # build design Xp from X_train_unscaled aligned with yM_train ordering\n",
        "    Xp = np.vstack([X_train_unscaled[idx_comp_mask, FEATURES.index(c)] for c in pred_cols]).T\n",
        "    y_comp_mass = yM_train[idx_comp_mask]\n",
        "\n",
        "    # robust RANSAC fit for mass multi-linear prior\n",
        "    base_lr = LinearRegression()\n",
        "    ransac = RANSACRegressor(estimator=base_lr, min_samples=0.5, residual_threshold=1.0, random_state=SEED)\n",
        "    ransac.fit(Xp, y_comp_mass)\n",
        "    coef = ransac.estimator_.coef_.astype(float)\n",
        "    intercept = float(ransac.estimator_.intercept_)\n",
        "\n",
        "    # MS prior: logSFR ~ A + B * logM  (robust via RANSAC)\n",
        "    Xm = yM_train[idx_comp_mask].reshape(-1,1)\n",
        "    ys_comp = yS_train[idx_comp_mask]\n",
        "    ransac_ms = RANSACRegressor(estimator=LinearRegression(), min_samples=0.5, residual_threshold=0.5, random_state=SEED)\n",
        "    ransac_ms.fit(Xm, ys_comp)\n",
        "    A = float(ransac_ms.estimator_.intercept_)\n",
        "    B = float(ransac_ms.estimator_.coef_[0])\n",
        "\n",
        "    clusters[f\"cluster_{comp}\"] = {\n",
        "        \"n_train\": int(n_comp),\n",
        "        \"mass_multi\": {\"intercept\": intercept, \"coeffs\": dict(zip(pred_cols, coef.tolist())), \"predictor_order\": pred_cols},\n",
        "        \"MS\": {\"A\": A, \"B\": B}\n",
        "    }\n",
        "\n",
        "# --- Compatibility 2-term prior on the currently active training set (g-r, M_r) ---\n",
        "X2 = np.vstack([\n",
        "    X_train_unscaled[:, FEATURES.index('g-r')],\n",
        "    X_train_unscaled[:, FEATURES.index('M_r')]\n",
        "]).T\n",
        "lr2 = LinearRegression().fit(X2, yM_train)\n",
        "a2 = float(lr2.intercept_)\n",
        "# coef_ may be 1d length-2\n",
        "b2, c2 = float(lr2.coef_[0]), float(lr2.coef_[1])\n",
        "print(\"Compatibility 2-term prior fitted on rows:\", X_train_unscaled.shape[0], \"a2,b2,c2:\", a2, b2, c2)\n",
        "\n",
        "# --- Overall robust prior on whole (active) training set using RANSAC too ---\n",
        "def fit_mass_prior_robust(X_unscaled, y_arr):\n",
        "    pred_cols = ['g-r','u-g','M_r','redshift']\n",
        "    X_train_mass = np.vstack([X_unscaled[:, FEATURES.index(c)] for c in pred_cols]).T\n",
        "    y_train_mass = y_arr\n",
        "    base_lr = LinearRegression()\n",
        "    ransac = RANSACRegressor(estimator=base_lr, min_samples=0.5, residual_threshold=1.0, random_state=SEED)\n",
        "    ransac.fit(X_train_mass, y_train_mass)\n",
        "    coef = ransac.estimator_.coef_.astype(float)\n",
        "    intercept = float(ransac.estimator_.intercept_)\n",
        "    return intercept, dict(zip(pred_cols, coef.tolist())), pred_cols\n",
        "\n",
        "intercept_all, coeffs_all, pred_order_all = fit_mass_prior_robust(X_train_unscaled, yM_train)\n",
        "\n",
        "# average MS A,B across clusters (safe if both clusters present)\n",
        "A_all = float((clusters['cluster_0']['MS']['A'] + clusters['cluster_1']['MS']['A'])/2.0)\n",
        "B_all = float((clusters['cluster_0']['MS']['B'] + clusters['cluster_1']['MS']['B'])/2.0)\n",
        "\n",
        "priors = {\n",
        "    \"clusters\": clusters,\n",
        "    \"mass_multi\": {\"intercept\": intercept_all, \"coeffs\": coeffs_all, \"predictor_order\": pred_order_all, \"n_train\": int(X_train_unscaled.shape[0])},\n",
        "    \"a\": a2, \"b\": float(b2), \"c\": float(c2),\n",
        "    \"MS_overall\": {\"A\": A_all, \"B\": B_all},\n",
        "}\n",
        "\n",
        "# save\n",
        "os.makedirs(EXP_ROOT, exist_ok=True)\n",
        "with open(os.path.join(EXP_ROOT, \"priors.json\"), \"w\") as f:\n",
        "    json.dump(priors, f, indent=2)\n",
        "\n",
        "print(\"Saved clustered priors. cluster sizes (train):\", {k: v['n_train'] for k, v in clusters.items()})\n",
        "print(\"Saved priors.json to\", os.path.join(EXP_ROOT, \"priors.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056841575
        }
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Cell 6 — Baseline RFs\n",
        "# ----------------------\n",
        "rf_params = dict(n_estimators=50, max_depth=20, n_jobs=1, random_state=SEED)\n",
        "print(\"Training RF with params:\", rf_params)\n",
        "rf_m = RandomForestRegressor(**rf_params)\n",
        "rf_s = RandomForestRegressor(**rf_params)\n",
        "t0 = time.time()\n",
        "rf_m.fit(X_train_s, yM_train)\n",
        "rf_s.fit(X_train_s, yS_train)\n",
        "t_rf = time.time() - t0\n",
        "print(\"RF training time (s):\", t_rf)\n",
        "m_rf_pred = rf_m.predict(X_test_s)\n",
        "s_rf_pred = rf_s.predict(X_test_s)\n",
        "print(\"RF mass metrics:\", metrics(yM_test, m_rf_pred))\n",
        "print(\"RF sfr metrics:\", metrics(yS_test, s_rf_pred))\n",
        "joblib.dump(rf_m, os.path.join(EXP_ROOT, \"rf_mass.joblib\"))\n",
        "joblib.dump(rf_s, os.path.join(EXP_ROOT, \"rf_sfr.joblib\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056881497
        }
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Stage A — deterministic multitask PINN (pretrain)\n",
        "# ----------------------\n",
        "class MTNN_det(nn.Module):\n",
        "    \"\"\"\n",
        "    Stage A: Deterministic Physics-Informed Neural Network\n",
        "    Predicts physically bounded logM and logSFR\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared encoder\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Raw heads (bounded via tanh)\n",
        "        self.m_head = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.s_head = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Physical bounds\n",
        "        # logM ∈ [5, 13] → center=9, half-range=4\n",
        "        self.M_CENTER = 9.0\n",
        "        self.M_SCALE  = 4.0\n",
        "\n",
        "        # logSFR ∈ [-5, 2] → center=-1.5, half-range=3.5\n",
        "        self.S_CENTER = -1.5\n",
        "        self.S_SCALE  = 3.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.shared(x)\n",
        "\n",
        "        # Raw bounded outputs in (-1, 1)\n",
        "        m_raw = self.m_head(h).squeeze(-1)\n",
        "        s_raw = self.s_head(h).squeeze(-1)\n",
        "\n",
        "        # Rescale to physical ranges\n",
        "        m_mu = self.M_CENTER + self.M_SCALE * m_raw\n",
        "        s_mu = self.S_CENTER + self.S_SCALE * s_raw\n",
        "\n",
        "        return m_mu, s_mu\n",
        "\n",
        "batch_A = 512\n",
        "train_ds = TensorDataset(torch.tensor(X_train_s, dtype=torch.float32),\n",
        "                         torch.tensor(yM_train, dtype=torch.float32),\n",
        "                         torch.tensor(yS_train, dtype=torch.float32))\n",
        "val_ds = TensorDataset(torch.tensor(X_val_s, dtype=torch.float32),\n",
        "                       torch.tensor(yM_val, dtype=torch.float32),\n",
        "                       torch.tensor(yS_val, dtype=torch.float32))\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_A, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1024, shuffle=False)\n",
        "\n",
        "modelA = MTNN_det(X_train_s.shape[1]).to(DEVICE)\n",
        "optA = Adam(modelA.parameters(), lr=5e-4, weight_decay=1e-6)\n",
        "epochsA = QUICK_EPOCHS_A if USE_QUICK else 50\n",
        "clip_norm = 5.0\n",
        "\n",
        "# load priors\n",
        "with open(os.path.join(EXP_ROOT, \"priors.json\"), \"r\") as f:\n",
        "    pri = json.load(f)\n",
        "pri_a = float(pri.get('a', 0.0)); pri_b = float(pri.get('b', 0.0)); pri_c = float(pri.get('c', 0.0))\n",
        "pri_A = float(pri.get('MS_overall', {}).get('A', 0.0)); pri_B = float(pri.get('MS_overall', {}).get('B', 0.0))\n",
        "LAMBDA_MASS = 0.02; LAMBDA_MS = 0.02\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "best_val = 1e12; best_stateA = None\n",
        "for epoch in range(1, epochsA+1):\n",
        "    modelA.train()\n",
        "    losses = []\n",
        "    for Xb, ym, ys in train_loader:\n",
        "        Xb = Xb.to(DEVICE); ym = ym.to(DEVICE); ys = ys.to(DEVICE)\n",
        "        m_p, s_p = modelA(Xb)\n",
        "        L_data = mse_loss(m_p, ym) + mse_loss(s_p, ys)\n",
        "        # mass prior computed on original scale\n",
        "        Xb_un = scaler.inverse_transform(Xb.cpu().numpy())\n",
        "        mass_prior = pri_a + pri_b * Xb_un[:, FEATURES.index('g-r')] + pri_c * Xb_un[:, FEATURES.index('M_r')]\n",
        "        mass_prior_t = torch.tensor(mass_prior, dtype=torch.float32, device=DEVICE)\n",
        "        L_mass = mse_loss(m_p, mass_prior_t)\n",
        "        L_MS = mse_loss(s_p, pri_A + pri_B * m_p.detach())\n",
        "        L_total = L_data + LAMBDA_MASS * L_mass + LAMBDA_MS * L_MS\n",
        "        optA.zero_grad(); L_total.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(modelA.parameters(), clip_norm)\n",
        "        optA.step()\n",
        "        losses.append(float(L_total.detach().cpu().numpy()))\n",
        "    # val\n",
        "    modelA.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = []; trues = []\n",
        "        for Xb, ym, ys in val_loader:\n",
        "            Xb = Xb.to(DEVICE)\n",
        "            m_p, s_p = modelA(Xb)\n",
        "            preds.append(m_p.cpu().numpy()); trues.append(ym.numpy())\n",
        "    val_mse = mean_squared_error(np.concatenate(trues), np.concatenate(preds))\n",
        "    if val_mse < best_val:\n",
        "        best_val = val_mse\n",
        "        best_stateA = {k:v.cpu() for k,v in modelA.state_dict().items()}\n",
        "    if epoch % 5 == 0 or epoch == 1:\n",
        "        print(f\"[Stage A] Epoch {epoch:03d} train_loss={np.mean(losses):.6f} val_mse={val_mse:.6f}\")\n",
        "\n",
        "torch.save(best_stateA, os.path.join(EXP_ROOT,\"pinn_stageA_best.pth\"))\n",
        "print(\"Saved Stage A best.\")\n",
        "\n",
        "# Build Context wrapper from Stage A (only if Stage A actually trained)\n",
        "class ContextNetWrapper(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(dim,256), nn.ReLU(),\n",
        "            nn.Linear(256,128), nn.ReLU()\n",
        "        )\n",
        "        self.context_net = nn.Sequential(\n",
        "            nn.Linear(128,64), nn.ReLU(),\n",
        "            nn.Linear(64,64), nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.context_net(self.encoder(x))\n",
        "\n",
        "ctx_model = ContextNetWrapper(X_train_s.shape[1]).to(DEVICE)\n",
        "\n",
        "if best_stateA is not None:\n",
        "    # Map weights from modelA.shared -> ctx_model.encoder\n",
        "    sdA = best_stateA\n",
        "    mapping = {\n",
        "        'encoder.0.weight':'shared.0.weight',\n",
        "        'encoder.0.bias':'shared.0.bias',\n",
        "        'encoder.2.weight':'shared.2.weight',\n",
        "        'encoder.2.bias':'shared.2.bias'\n",
        "    }\n",
        "    sd_ctx = ctx_model.state_dict()\n",
        "    for t_key, s_key in mapping.items():\n",
        "        if s_key in sdA and t_key in sd_ctx:\n",
        "            sd_ctx[t_key] = sdA[s_key]\n",
        "    ctx_model.load_state_dict(sd_ctx)\n",
        "    for p in ctx_model.parameters():\n",
        "        p.requires_grad = False\n",
        "    print(\"Context model prepared from Stage A weights (frozen).\")\n",
        "else:\n",
        "    # Stage A was skipped; leave context model randomly initialized\n",
        "    print(\"Stage A skipped; context model initialized randomly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056882033
        }
      },
      "outputs": [],
      "source": [
        "# ===== Stage A evaluation ONLY =====\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "modelA.eval()\n",
        "with torch.no_grad():\n",
        "    X_t = torch.tensor(X_test_s, dtype=torch.float32).to(DEVICE)\n",
        "    m_mu, s_mu = modelA(X_t)\n",
        "\n",
        "mu_m = m_mu.cpu().numpy()\n",
        "mu_s = s_mu.cpu().numpy()\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
        "        \"r2\": r2_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "print(\"Stage A mass metrics:\", metrics(yM_test, mu_m))\n",
        "print(\"Stage A sfr metrics :\", metrics(yS_test, mu_s))\n",
        "print(\"mu_m range:\", mu_m.min(), mu_m.max())\n",
        "print(\"mu_s range:\", mu_s.min(), mu_s.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056887233
        }
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Stage B — flow-only training (conditional flow for Q)\n",
        "# ----------------------\n",
        "\n",
        "def build_conditional_maf(context_dim, n_blocks=4, hidden_features=64):\n",
        "    transforms = []\n",
        "    for _ in range(n_blocks):\n",
        "        transforms.append(\n",
        "            MaskedAffineAutoregressiveTransform(\n",
        "                features=1,\n",
        "                hidden_features=hidden_features,\n",
        "                context_features=context_dim,\n",
        "                num_blocks=2,\n",
        "                use_residual_blocks=False\n",
        "            )\n",
        "        )\n",
        "        transforms.append(ReversePermutation(features=1))\n",
        "    transform = CompositeTransform(transforms)\n",
        "    base_dist = StandardNormal([1])\n",
        "    return Flow(transform, base_dist)\n",
        "\n",
        "\n",
        "# ---- Instantiate flow ----\n",
        "context_dim = 64\n",
        "flow = build_conditional_maf(\n",
        "    context_dim=context_dim,\n",
        "    n_blocks=4,\n",
        "    hidden_features=64\n",
        ").to(DEVICE)\n",
        "\n",
        "opt_flow = Adam(flow.parameters(), lr=3e-4, weight_decay=1e-6)\n",
        "epochsB = QUICK_EPOCHS_B if USE_QUICK else 40\n",
        "\n",
        "# ---- Identify quenched component from GMM (fit earlier on train) ----\n",
        "comp_means_sfr = gmm.means_[:, 1]\n",
        "quenched_comp = int(np.argmin(comp_means_sfr))\n",
        "print(\"GMM train means (logSFR):\", comp_means_sfr, \"-> quenched:\", quenched_comp)\n",
        "\n",
        "train_loader_flow = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "\n",
        "best_flow_state = None\n",
        "best_flow_loss = float(\"inf\")\n",
        "\n",
        "# ----------------------\n",
        "# Training loop\n",
        "# ----------------------\n",
        "for epoch in range(1, epochsB + 1):\n",
        "    flow.train()\n",
        "    losses = []\n",
        "\n",
        "    for Xb, ym, ys in train_loader_flow:\n",
        "        Xb = Xb.to(DEVICE).float()\n",
        "\n",
        "        # ---- Context from frozen encoder ----\n",
        "        with torch.no_grad():\n",
        "            ctx = ctx_model(Xb)\n",
        "        ctx = ctx.detach()  # 🔒 critical: prevent any leakage / gradients\n",
        "\n",
        "        # ---- Soft quenching target from GMM ----\n",
        "        ym_np = ym.numpy()\n",
        "        ys_np = ys.numpy()\n",
        "        q_target = gmm.predict_proba(\n",
        "            np.vstack([ym_np, ys_np]).T\n",
        "        )[:, quenched_comp].astype(np.float32)\n",
        "\n",
        "        q_t = torch.tensor(q_target, device=DEVICE).unsqueeze(-1)\n",
        "\n",
        "        # ---- Flow NLL ----\n",
        "        nll = -flow.log_prob(q_t, context=ctx).mean()\n",
        "\n",
        "        opt_flow.zero_grad()\n",
        "        nll.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(flow.parameters(), 5.0)\n",
        "        opt_flow.step()\n",
        "\n",
        "        losses.append(float(nll.detach().cpu()))\n",
        "\n",
        "    avg_nll = float(np.mean(losses))\n",
        "    if avg_nll < best_flow_loss:\n",
        "        best_flow_loss = avg_nll\n",
        "        best_flow_state = {k: v.cpu() for k, v in flow.state_dict().items()}\n",
        "\n",
        "    if epoch % 5 == 0 or epoch == 1:\n",
        "        print(f\"[Stage B] Epoch {epoch:03d} flow_nll={avg_nll:.6f}\")\n",
        "\n",
        "# ----------------------\n",
        "# Save best flow\n",
        "# ----------------------\n",
        "if best_flow_state is not None:\n",
        "    torch.save(\n",
        "        best_flow_state,\n",
        "        os.path.join(EXP_ROOT, \"pinn_flow_stageB_flow.pth\")\n",
        "    )\n",
        "    print(\"Saved Stage B flow.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056898267
        }
      },
      "outputs": [],
      "source": [
        "# %% Cell 7C — Stage C: Joint fine-tune (bounded, safe, copy-paste ready)\n",
        "import os, math, json, numpy as np, random, torch, torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Deterministic seed\n",
        "np.random.seed(SEED); random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Stage C running on device:\", DEVICE)\n",
        "\n",
        "# --- Fallback: ensure loaders exist ---\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "if 'train_loader' not in globals() or 'val_loader' not in globals():\n",
        "    print(\"Fallback: creating train/val DataLoaders from arrays.\")\n",
        "    batch_train = globals().get('BATCH_TRAIN', 512)\n",
        "    batch_val = globals().get('BATCH_VAL', 1024)\n",
        "    train_ds = TensorDataset(torch.tensor(X_train_s,dtype=torch.float32),\n",
        "                             torch.tensor(yM_train,dtype=torch.float32),\n",
        "                             torch.tensor(yS_train,dtype=torch.float32))\n",
        "    val_ds = TensorDataset(torch.tensor(X_val_s,dtype=torch.float32),\n",
        "                           torch.tensor(yM_val,dtype=torch.float32),\n",
        "                           torch.tensor(yS_val,dtype=torch.float32))\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_train, shuffle=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=batch_val, shuffle=False)\n",
        "    print(\"Created fallback loaders. Train size:\", len(train_ds), \"Val size:\", len(val_ds))\n",
        "\n",
        "# ----------------------\n",
        "# Joint model (BOUNDED means)\n",
        "# ----------------------\n",
        "class PINNJoint(nn.Module):\n",
        "    def __init__(self, dim, context_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared encoder (same as Stage A)\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(dim,256), nn.ReLU(),\n",
        "            nn.Linear(256,128), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Raw bounded heads\n",
        "        self.m_head = nn.Sequential(nn.Linear(128,1), nn.Tanh())\n",
        "        self.s_head = nn.Sequential(nn.Linear(128,1), nn.Tanh())\n",
        "\n",
        "        # Heteroscedastic log-variance heads\n",
        "        self.m_logvar = nn.Linear(128,1)\n",
        "        self.s_logvar = nn.Linear(128,1)\n",
        "\n",
        "        # Context net for flow\n",
        "        self.context_net = nn.Sequential(\n",
        "            nn.Linear(128,context_dim), nn.ReLU(),\n",
        "            nn.Linear(context_dim,context_dim), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Physical bounds (same as Stage A)\n",
        "        # logM ∈ [5, 13]\n",
        "        self.M_CENTER = 9.0\n",
        "        self.M_SCALE  = 4.0\n",
        "        # logSFR ∈ [-5, 2]\n",
        "        self.S_CENTER = -1.5\n",
        "        self.S_SCALE  = 3.5\n",
        "\n",
        "        self.context_dim = context_dim\n",
        "        self.flow = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.shared(x)\n",
        "\n",
        "        # bounded means\n",
        "        m_raw = self.m_head(h).squeeze(-1)\n",
        "        s_raw = self.s_head(h).squeeze(-1)\n",
        "\n",
        "        m_mu = self.M_CENTER + self.M_SCALE * m_raw\n",
        "        s_mu = self.S_CENTER + self.S_SCALE * s_raw\n",
        "\n",
        "        # log-variances\n",
        "        m_logvar = self.m_logvar(h).squeeze(-1)\n",
        "        s_logvar = self.s_logvar(h).squeeze(-1)\n",
        "\n",
        "        ctx = self.context_net(h)\n",
        "\n",
        "        return {\n",
        "            \"context\": ctx,\n",
        "            \"mu_mass\": m_mu,\n",
        "            \"logvar_mass\": m_logvar,\n",
        "            \"mu_sfr\": s_mu,\n",
        "            \"logvar_sfr\": s_logvar\n",
        "        }\n",
        "\n",
        "# ----------------------\n",
        "# Flow builder\n",
        "# ----------------------\n",
        "def build_conditional_maf(context_dim, n_blocks=6, hidden_features=128):\n",
        "    from nflows.flows import Flow\n",
        "    from nflows.distributions import StandardNormal\n",
        "    from nflows.transforms import CompositeTransform, MaskedAffineAutoregressiveTransform, ReversePermutation\n",
        "    transforms = []\n",
        "    for _ in range(n_blocks):\n",
        "        transforms.append(MaskedAffineAutoregressiveTransform(\n",
        "            features=1,\n",
        "            hidden_features=hidden_features,\n",
        "            context_features=context_dim,\n",
        "            num_blocks=2,\n",
        "            use_residual_blocks=False\n",
        "        ))\n",
        "        transforms.append(ReversePermutation(features=1))\n",
        "    return Flow(CompositeTransform(transforms), StandardNormal([1]))\n",
        "\n",
        "# ----------------------\n",
        "# Instantiate joint model\n",
        "# ----------------------\n",
        "context_dim = 64\n",
        "joint = PINNJoint(X_train_s.shape[1], context_dim=context_dim).to(DEVICE)\n",
        "\n",
        "# --- Load Stage A weights (shared encoder only) ---\n",
        "p_stageA = os.path.join(EXP_ROOT, \"pinn_stageA_best.pth\")\n",
        "if os.path.exists(p_stageA):\n",
        "    sdA = torch.load(p_stageA, map_location='cpu')\n",
        "    joint_sd = joint.state_dict()\n",
        "    copied = 0\n",
        "    for k,v in sdA.items():\n",
        "        if k in joint_sd and joint_sd[k].shape == v.shape:\n",
        "            joint_sd[k].copy_(v)\n",
        "            copied += 1\n",
        "    joint.load_state_dict(joint_sd)\n",
        "    print(f\"Loaded Stage A weights (copied {copied} params).\")\n",
        "\n",
        "# --- Load Stage B flow (infer architecture if needed) ---\n",
        "p_flowB = os.path.join(EXP_ROOT, \"pinn_flow_stageB_flow.pth\")\n",
        "flow_loaded = False\n",
        "if os.path.exists(p_flowB):\n",
        "    try:\n",
        "        joint.flow = build_conditional_maf(context_dim, n_blocks=4, hidden_features=64).to(DEVICE)\n",
        "        joint.flow.load_state_dict(torch.load(p_flowB, map_location='cpu'))\n",
        "        flow_loaded = True\n",
        "        print(\"Loaded Stage B flow.\")\n",
        "    except Exception as e:\n",
        "        print(\"Flow load issue:\", e)\n",
        "\n",
        "if not flow_loaded:\n",
        "    joint.flow = build_conditional_maf(context_dim, n_blocks=4, hidden_features=64).to(DEVICE)\n",
        "    print(\"Using randomly initialized flow.\")\n",
        "\n",
        "# ----------------------\n",
        "# Optimizer & config\n",
        "# ----------------------\n",
        "for p in joint.parameters(): p.requires_grad = True\n",
        "for p in joint.flow.parameters(): p.requires_grad = True\n",
        "\n",
        "opt = Adam(list(joint.parameters()) + list(joint.flow.parameters()), lr=1e-4, weight_decay=1e-6)\n",
        "epochsC = globals().get('epochsC', 20)\n",
        "clip_norm = 5.0\n",
        "\n",
        "LOGVAR_MIN, LOGVAR_MAX = -10.0, 5.0\n",
        "\n",
        "def gaussian_nll_torch(y, mu, logvar):\n",
        "    logvar = torch.clamp(logvar, LOGVAR_MIN, LOGVAR_MAX)\n",
        "    var = torch.exp(logvar)\n",
        "    return 0.5 * ((y - mu)**2 / var + logvar + math.log(2*math.pi))\n",
        "\n",
        "# ----------------------\n",
        "# Priors & GMM\n",
        "# ----------------------\n",
        "with open(os.path.join(EXP_ROOT, \"priors.json\"), \"r\") as f:\n",
        "    pri = json.load(f)\n",
        "\n",
        "pri_a = float(pri.get('a',0)); pri_b = float(pri.get('b',0)); pri_c = float(pri.get('c',0))\n",
        "A_all = float(pri.get('MS_overall',{}).get('A',0))\n",
        "B_all = float(pri.get('MS_overall',{}).get('B',0))\n",
        "\n",
        "LAMBDA_MASS = 0.02; LAMBDA_MS = 0.02; LAMBDA_Q = 1.0; LAMBDA_Q_PHYS = 0.5\n",
        "\n",
        "gmm_train = GaussianMixture(n_components=2, covariance_type='full', random_state=SEED)\n",
        "gmm_train.fit(np.vstack([yM_train, yS_train]).T)\n",
        "quenched_comp = int(np.argmin(gmm_train.means_[:,1]))\n",
        "\n",
        "# ----------------------\n",
        "# Training loop (uncomment to run)\n",
        "# ----------------------\n",
        "best_val = 1e12; best_state = None; best_flow_state = None\n",
        "\n",
        "for epoch in range(1, epochsC+1):\n",
        "    joint.train(); joint.flow.train()\n",
        "    losses = []\n",
        "    for Xb, ym, ys in train_loader:\n",
        "        Xb = Xb.to(DEVICE); ym = ym.to(DEVICE); ys = ys.to(DEVICE)\n",
        "        out = joint(Xb)\n",
        "        ctx = out[\"context\"]\n",
        "        m_mu = out[\"mu_mass\"]; s_mu = out[\"mu_sfr\"]\n",
        "        m_lv = torch.clamp(out[\"logvar_mass\"], LOGVAR_MIN, LOGVAR_MAX)\n",
        "        s_lv = torch.clamp(out[\"logvar_sfr\"], LOGVAR_MIN, LOGVAR_MAX)\n",
        "\n",
        "        L_data = gaussian_nll_torch(ym, m_mu, m_lv).mean() + gaussian_nll_torch(ys, s_mu, s_lv).mean()\n",
        "\n",
        "        Xb_un = scaler.inverse_transform(Xb.cpu().numpy())\n",
        "        mass_prior = pri_a + pri_b*Xb_un[:,FEATURES.index('g-r')] + pri_c*Xb_un[:,FEATURES.index('M_r')]\n",
        "        L_mass = nn.functional.mse_loss(m_mu, torch.tensor(mass_prior, device=DEVICE))\n",
        "        L_MS = nn.functional.mse_loss(s_mu, A_all + B_all*m_mu.detach())\n",
        "\n",
        "        q_t = torch.tensor(\n",
        "            gmm_train.predict_proba(np.vstack([ym.cpu().numpy(), ys.cpu().numpy()]).T)[:,quenched_comp],\n",
        "            device=DEVICE\n",
        "        ).unsqueeze(-1)\n",
        "\n",
        "        nll_q = -joint.flow.log_prob(q_t, context=ctx.detach()).mean()\n",
        "\n",
        "        L = L_data + LAMBDA_MASS*L_mass + LAMBDA_MS*L_MS + LAMBDA_Q*nll_q\n",
        "        opt.zero_grad(); L.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(list(joint.parameters())+list(joint.flow.parameters()), clip_norm)\n",
        "        opt.step()\n",
        "        losses.append(L.item())\n",
        "\n",
        "    print(f\"[Stage C] Epoch {epoch:03d} loss={np.mean(losses):.4f}\")\n",
        "\n",
        "# ----------------------\n",
        "# Save FINAL Stage C model (REQUIRED)\n",
        "# ----------------------\n",
        "torch.save(joint.state_dict(), os.path.join(EXP_ROOT, \"pinn_stageC_joint_final.pth\"))\n",
        "torch.save(joint.flow.state_dict(), os.path.join(EXP_ROOT, \"pinn_stageC_flow_final.pth\"))\n",
        "\n",
        "print(\"Saved final Stage C joint model and flow.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1766056904370
        }
      },
      "outputs": [],
      "source": [
        "# %% Final Evaluation — Stage C (memory-safe, paper-ready)\n",
        "\n",
        "import os, json, math, numpy as np, torch\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    roc_auc_score, brier_score_loss\n",
        ")\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Evaluation running on device:\", DEVICE)\n",
        "\n",
        "# ----------------------\n",
        "# Load trained Stage C model\n",
        "# ----------------------\n",
        "joint.eval()\n",
        "joint.flow.eval()\n",
        "\n",
        "# ----------------------\n",
        "# Helpers\n",
        "# ----------------------\n",
        "def metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"rmse\": float(np.sqrt(mean_squared_error(y_true, y_pred))),\n",
        "        \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
        "        \"r2\":  float(r2_score(y_true, y_pred))\n",
        "    }\n",
        "\n",
        "def gaussian_nll(y, mu, logvar):\n",
        "    logvar = np.clip(logvar, -10.0, 5.0)\n",
        "    var = np.exp(logvar)\n",
        "    return 0.5 * ((y - mu)**2 / var + logvar + np.log(2*np.pi))\n",
        "\n",
        "# ----------------------\n",
        "# Batched forward pass\n",
        "# ----------------------\n",
        "BATCH_EVAL = 2048\n",
        "N = len(X_test_s)\n",
        "\n",
        "mu_m, mu_s = [], []\n",
        "lv_m, lv_s = [], []\n",
        "contexts = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, N, BATCH_EVAL):\n",
        "        xb = torch.tensor(\n",
        "            X_test_s[i:i+BATCH_EVAL],\n",
        "            dtype=torch.float32,\n",
        "            device=DEVICE\n",
        "        )\n",
        "        out = joint(xb)\n",
        "\n",
        "        mu_m.append(out[\"mu_mass\"].cpu().numpy())\n",
        "        mu_s.append(out[\"mu_sfr\"].cpu().numpy())\n",
        "        lv_m.append(out[\"logvar_mass\"].cpu().numpy())\n",
        "        lv_s.append(out[\"logvar_sfr\"].cpu().numpy())\n",
        "        contexts.append(out[\"context\"].cpu())\n",
        "\n",
        "mu_m = np.concatenate(mu_m)\n",
        "mu_s = np.concatenate(mu_s)\n",
        "lv_m = np.concatenate(lv_m)\n",
        "lv_s = np.concatenate(lv_s)\n",
        "contexts = torch.cat(contexts, dim=0)\n",
        "\n",
        "sig_m = np.sqrt(np.exp(lv_m))\n",
        "sig_s = np.sqrt(np.exp(lv_s))\n",
        "\n",
        "# ----------------------\n",
        "# Regression metrics\n",
        "# ----------------------\n",
        "mass_metrics = metrics(yM_test, mu_m)\n",
        "sfr_metrics  = metrics(yS_test, mu_s)\n",
        "\n",
        "nll_mass = float(np.mean(gaussian_nll(yM_test, mu_m, lv_m)))\n",
        "nll_sfr  = float(np.mean(gaussian_nll(yS_test, mu_s, lv_s)))\n",
        "\n",
        "print(\"PINN mass metrics:\", mass_metrics)\n",
        "print(\"PINN sfr metrics :\", sfr_metrics)\n",
        "print(\"Gaussian NLL mass / sfr:\", nll_mass, nll_sfr)\n",
        "\n",
        "# ----------------------\n",
        "# Quenching posterior (flow sampling)\n",
        "# ----------------------\n",
        "N_SAMPLES_Q = 50   # safe on CPU\n",
        "q_means = []\n",
        "q_stds  = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, N, BATCH_EVAL):\n",
        "        ctx = contexts[i:i+BATCH_EVAL].to(DEVICE)\n",
        "\n",
        "        # flow returns (S, B, 1)\n",
        "        qs = joint.flow.sample(N_SAMPLES_Q, context=ctx)\n",
        "        qs = qs.squeeze(-1).cpu().numpy()   # (S, B)\n",
        "\n",
        "        # transpose → (B, S)\n",
        "        qs = qs.T\n",
        "\n",
        "        q_means.append(qs.mean(axis=1))\n",
        "        q_stds.append(qs.std(axis=1))\n",
        "\n",
        "q_mean = np.concatenate(q_means, axis=0)   # (N,)\n",
        "q_std  = np.concatenate(q_stds, axis=0)    # (N,)\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Optional classification metrics (if labels exist)\n",
        "# ----------------------\n",
        "q_metrics = {}\n",
        "if \"gmm_train\" in globals():\n",
        "    q_true = gmm_train.predict_proba(\n",
        "        np.vstack([yM_test, yS_test]).T\n",
        "    )[:, quenched_comp]\n",
        "\n",
        "    try:\n",
        "        q_metrics[\"auc\"] = float(roc_auc_score(q_true, q_mean))\n",
        "        q_metrics[\"brier\"] = float(brier_score_loss(q_true, q_mean))\n",
        "        print(\"Q metrics:\", q_metrics)\n",
        "    except Exception as e:\n",
        "        print(\"Q metrics skipped:\", e)\n",
        "\n",
        "# ----------------------\n",
        "# Save evaluation summary\n",
        "# ----------------------\n",
        "summary = {\n",
        "    \"mass_metrics\": mass_metrics,\n",
        "    \"sfr_metrics\": sfr_metrics,\n",
        "    \"nll_mass\": nll_mass,\n",
        "    \"nll_sfr\": nll_sfr,\n",
        "    \"q_metrics\": q_metrics,\n",
        "    \"uncertainty_stats\": {\n",
        "        \"sigma_mass_median\": float(np.median(sig_m)),\n",
        "        \"sigma_sfr_median\":  float(np.median(sig_s)),\n",
        "        \"q_std_median\":      float(np.median(q_std))\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(os.path.join(EXP_ROOT, \"evaluation.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"Saved evaluation.json to\", EXP_ROOT)\n",
        "print(\"Evaluation complete.\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
